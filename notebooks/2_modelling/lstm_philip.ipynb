{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = pd.read_parquet(\"../../data/preprocessed/holdout_1.pq\") # , engine='pyarrow'\n",
    "train_y = pd.read_parquet(\"../../data/preprocessed/holdout_1_y.pq\")\n",
    "test_x = pd.read_parquet(\"../../data/preprocessed/thursdays.pq\")\n",
    "test_y = pd.read_parquet(\"../../data/preprocessed/thursdays_y.pq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "478807"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Loss: 0.0256, MAE: 0.0172\n",
      "Epoch 2/30, Loss: 0.0220, MAE: 0.0061\n",
      "Epoch 3/30, Loss: 0.0215, MAE: 0.0069\n",
      "Epoch 4/30, Loss: 0.0211, MAE: 0.0093\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "target_column = 'ProzessData_ActData_AB1_Temperature_DR1_MassMixingStage'\n",
    "\n",
    "# Normalize features in train_x (excluding the timestamp column)\n",
    "scaler_x = MinMaxScaler()\n",
    "train_x_scaled = scaler_x.fit_transform(train_x.iloc[:, 1:])  # Adjust if the first column isn't the timestamp\n",
    "\n",
    "# Normalize the target column in train_y\n",
    "scaler_y = MinMaxScaler()\n",
    "train_y_scaled = scaler_y.fit_transform(train_y[[target_column]])\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "train_x_tensor = torch.tensor(train_x_scaled).float().unsqueeze(1)  # Add time step dimension\n",
    "train_y_tensor = torch.tensor(train_y_scaled).float()\n",
    "\n",
    "# DataLoader\n",
    "train_dataset = TensorDataset(train_x_tensor, train_y_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# LSTM model\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        out = self.dropout(lstm_out[:, -1, :])\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "# Model initialization\n",
    "input_dim = train_x_tensor.shape[2]  # Number of features\n",
    "hidden_dim = 50  # Example value\n",
    "output_dim = train_y_tensor.shape[1]  # Should be 1 as we're predicting a single target\n",
    "\n",
    "model = LSTMModel(input_dim, hidden_dim, output_dim).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "\n",
    "num_epochs = 30\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    total_mae = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Calculate loss (MSE)\n",
    "        loss = criterion(outputs, labels)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Calculate MAE\n",
    "        #print(type(F.l1_loss(outputs, labels, reduction='sum').item()))\n",
    "        list1 = outputs.tolist()\n",
    "        list2 = labels.tolist()\n",
    "        list1 = np.array(list1).flatten()\n",
    "        list2 = np.array(list2).flatten()\n",
    "        abweichung = []\n",
    "        for a, b in zip(list1, list2):\n",
    "            \n",
    "            abweichung.append(abs(a - b))    # Give points\n",
    "        points = []\n",
    "        for diff in abweichung:\n",
    "            if diff < 0.05:\n",
    "                points.append(1.0)\n",
    "            elif 0.05 <= diff < 0.1:\n",
    "                points.append(0.5)\n",
    "            elif 0.1 <= diff < 0.5:\n",
    "                points.append(0.25)\n",
    "            else:\n",
    "                points.append(0) \n",
    "\n",
    "        list1 = points\n",
    "\n",
    "        points2 = [] \n",
    "        consecutive_count =0      \n",
    "        for i in range(0, len(list1)):\n",
    "            \n",
    "            if list1[i] >=0.5 and consecutive_count == 0 :\n",
    "\n",
    "                points2.append (1)\n",
    "\n",
    "            elif list1[i] >=0.5 and consecutive_count != 0:\n",
    "\n",
    "                if consecutive_count == 1:\n",
    "                    points2.append (.5)\n",
    "                    points2.append(1)\n",
    "        \n",
    "                elif 2 <= consecutive_count <= 10:\n",
    "                    points2.extend([0.25] * consecutive_count)\n",
    "                    points2.append(1)\n",
    "                else:\n",
    "                    points2.extend([0] * consecutive_count)\n",
    "                    points2.append(1)\n",
    "\n",
    "                consecutive_count = 0# Reset consecutive count\n",
    "\n",
    "            else:\n",
    "                consecutive_count+=1\n",
    "\n",
    "        \n",
    "        if consecutive_count == 1:\n",
    "            points2.append (.5)\n",
    "        elif 2 <= consecutive_count <= 10:\n",
    "            points2.extend([0.25] * consecutive_count)\n",
    "        else:\n",
    "            points2.extend([0] * consecutive_count)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        total = sum(points)+sum(points2) \n",
    "        maxpoint = len(points)*2\n",
    "\n",
    "        #print(\" Punkte aus abweichungslist:\", sum(points), \"Punkte aus Zeitabweichung:\", sum(points2), \"max Punkte:\",len(points))\n",
    "\n",
    "        #print(total/maxpoint)\n",
    "        \n",
    "        mae = ((maxpoint/total)-1)*10\n",
    "        total_mae += mae\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Average loss and MAE over the epoch\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    avg_mae = total_mae / len(train_loader.dataset)\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}, MAE: {avg_mae:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pickle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/OWL_Factory_Hackathon/notebooks/2_modelling/lstm_philip.ipynb Zelle 6\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bfictional-lamp-g66rv647gwvfpw6/workspaces/OWL_Factory_Hackathon/notebooks/2_modelling/lstm_philip.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m../../models/lstm_philip.pkl\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m file:\n\u001b[0;32m----> <a href='vscode-notebook-cell://codespaces%2Bfictional-lamp-g66rv647gwvfpw6/workspaces/OWL_Factory_Hackathon/notebooks/2_modelling/lstm_philip.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     pickle\u001b[39m.\u001b[39mdump(model, file)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pickle' is not defined"
     ]
    }
   ],
   "source": [
    "with open('../../models/lstm_philip2.pkl', 'wb') as file:\n",
    "    pickle.dump(model, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jhn_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "7ba48d1dfc31994510d1202d5cc1ad7c5341fe2fe772e21645b10ef4af5c8f4c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
