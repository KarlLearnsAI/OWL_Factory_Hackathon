{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pickle\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import xgboost as xgb\n",
    "import json\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1 Train Shapes [(478807, 18) / (478807, 1)]\n",
      "X1 Test Shapes [(273604, 18) / (273604, 1)]\n",
      "X2 Train Shapes [(478807, 18) / (478807, 1)]\n",
      "X2 Test Shapes [(273604, 18) / (273604, 1)]\n",
      "Index(['ProzessData_ActData_AB1_Analogs_DX1_MassPressure',\n",
      "       'ProzessData_ActData_AB1_Analogs_GY1_MassLevelTank',\n",
      "       'ProzessData_ActData_AB1_Current_DV1_Scraper',\n",
      "       'ProzessData_ActData_AB1_Current_DW1_RiserPumpFwd',\n",
      "       'ProzessData_ActData_AB1_Speed_DV1_Scraper',\n",
      "       'ProzessData_ActData_AB1_Speed_DW1_RiserPumpFwd',\n",
      "       'ProzessData_ActData_AB1_Temperature_DP1_MassHeatingStage',\n",
      "       'ProzessData_ActData_AB1_Temperature_DP1_WaterHeatingStage',\n",
      "       'ProzessData_ActData_AB1_Temperature_DQ1_MassCoolingStage',\n",
      "       'ProzessData_ActData_AB1_Temperature_DQ1_WaterCoolingStage',\n",
      "       'ProzessData_ActData_AB1_Temperature_DR1_WaterMixingStage',\n",
      "       'ProzessData_ActData_AB1_Temperature_DS1_WaterPipe',\n",
      "       'ProzessData_ActData_AB1_Temperature_DU1_WaterTank',\n",
      "       'ProzessData_ActData_AB1_Temperature_DX1_MassInfeed', 'hour', 'minute',\n",
      "       'day_time', 'night_time'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProzessData_ActData_AB1_Analogs_DX1_MassPressure</th>\n",
       "      <th>ProzessData_ActData_AB1_Analogs_GY1_MassLevelTank</th>\n",
       "      <th>ProzessData_ActData_AB1_Current_DV1_Scraper</th>\n",
       "      <th>ProzessData_ActData_AB1_Current_DW1_RiserPumpFwd</th>\n",
       "      <th>ProzessData_ActData_AB1_Speed_DV1_Scraper</th>\n",
       "      <th>ProzessData_ActData_AB1_Speed_DW1_RiserPumpFwd</th>\n",
       "      <th>ProzessData_ActData_AB1_Temperature_DP1_MassHeatingStage</th>\n",
       "      <th>ProzessData_ActData_AB1_Temperature_DP1_WaterHeatingStage</th>\n",
       "      <th>ProzessData_ActData_AB1_Temperature_DQ1_MassCoolingStage</th>\n",
       "      <th>ProzessData_ActData_AB1_Temperature_DQ1_WaterCoolingStage</th>\n",
       "      <th>ProzessData_ActData_AB1_Temperature_DR1_WaterMixingStage</th>\n",
       "      <th>ProzessData_ActData_AB1_Temperature_DS1_WaterPipe</th>\n",
       "      <th>ProzessData_ActData_AB1_Temperature_DU1_WaterTank</th>\n",
       "      <th>ProzessData_ActData_AB1_Temperature_DX1_MassInfeed</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>day_time</th>\n",
       "      <th>night_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-03-16 01:00:00+00:00</th>\n",
       "      <td>0.74</td>\n",
       "      <td>64.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.299999</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>41.599998</td>\n",
       "      <td>42.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>41.849998</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>41.900002</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-16 01:00:01+00:00</th>\n",
       "      <td>0.75</td>\n",
       "      <td>64.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.299999</td>\n",
       "      <td>42.099998</td>\n",
       "      <td>41.599998</td>\n",
       "      <td>42.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>41.849998</td>\n",
       "      <td>41.900002</td>\n",
       "      <td>41.900002</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-16 01:00:02+00:00</th>\n",
       "      <td>0.74</td>\n",
       "      <td>64.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.299999</td>\n",
       "      <td>42.099998</td>\n",
       "      <td>41.599998</td>\n",
       "      <td>42.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>41.849998</td>\n",
       "      <td>41.900002</td>\n",
       "      <td>41.900002</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-16 01:00:03+00:00</th>\n",
       "      <td>0.75</td>\n",
       "      <td>64.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.299999</td>\n",
       "      <td>42.099998</td>\n",
       "      <td>41.599998</td>\n",
       "      <td>42.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>41.849998</td>\n",
       "      <td>41.900002</td>\n",
       "      <td>41.900002</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-16 01:00:04+00:00</th>\n",
       "      <td>0.75</td>\n",
       "      <td>64.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.299999</td>\n",
       "      <td>42.099998</td>\n",
       "      <td>41.599998</td>\n",
       "      <td>42.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>41.849998</td>\n",
       "      <td>41.900002</td>\n",
       "      <td>41.900002</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           ProzessData_ActData_AB1_Analogs_DX1_MassPressure  \\\n",
       "2023-03-16 01:00:00+00:00                                              0.74   \n",
       "2023-03-16 01:00:01+00:00                                              0.75   \n",
       "2023-03-16 01:00:02+00:00                                              0.74   \n",
       "2023-03-16 01:00:03+00:00                                              0.75   \n",
       "2023-03-16 01:00:04+00:00                                              0.75   \n",
       "\n",
       "                           ProzessData_ActData_AB1_Analogs_GY1_MassLevelTank  \\\n",
       "2023-03-16 01:00:00+00:00                                              64.07   \n",
       "2023-03-16 01:00:01+00:00                                              64.07   \n",
       "2023-03-16 01:00:02+00:00                                              64.07   \n",
       "2023-03-16 01:00:03+00:00                                              64.07   \n",
       "2023-03-16 01:00:04+00:00                                              64.07   \n",
       "\n",
       "                           ProzessData_ActData_AB1_Current_DV1_Scraper  \\\n",
       "2023-03-16 01:00:00+00:00                                          0.0   \n",
       "2023-03-16 01:00:01+00:00                                          0.0   \n",
       "2023-03-16 01:00:02+00:00                                          0.0   \n",
       "2023-03-16 01:00:03+00:00                                          0.0   \n",
       "2023-03-16 01:00:04+00:00                                          0.0   \n",
       "\n",
       "                           ProzessData_ActData_AB1_Current_DW1_RiserPumpFwd  \\\n",
       "2023-03-16 01:00:00+00:00                                               0.0   \n",
       "2023-03-16 01:00:01+00:00                                               0.0   \n",
       "2023-03-16 01:00:02+00:00                                               0.0   \n",
       "2023-03-16 01:00:03+00:00                                               0.0   \n",
       "2023-03-16 01:00:04+00:00                                               0.0   \n",
       "\n",
       "                           ProzessData_ActData_AB1_Speed_DV1_Scraper  \\\n",
       "2023-03-16 01:00:00+00:00                                        0.0   \n",
       "2023-03-16 01:00:01+00:00                                        0.0   \n",
       "2023-03-16 01:00:02+00:00                                        0.0   \n",
       "2023-03-16 01:00:03+00:00                                        0.0   \n",
       "2023-03-16 01:00:04+00:00                                        0.0   \n",
       "\n",
       "                           ProzessData_ActData_AB1_Speed_DW1_RiserPumpFwd  \\\n",
       "2023-03-16 01:00:00+00:00                                             0.0   \n",
       "2023-03-16 01:00:01+00:00                                             0.0   \n",
       "2023-03-16 01:00:02+00:00                                             0.0   \n",
       "2023-03-16 01:00:03+00:00                                             0.0   \n",
       "2023-03-16 01:00:04+00:00                                             0.0   \n",
       "\n",
       "                           ProzessData_ActData_AB1_Temperature_DP1_MassHeatingStage  \\\n",
       "2023-03-16 01:00:00+00:00                                          41.299999          \n",
       "2023-03-16 01:00:01+00:00                                          41.299999          \n",
       "2023-03-16 01:00:02+00:00                                          41.299999          \n",
       "2023-03-16 01:00:03+00:00                                          41.299999          \n",
       "2023-03-16 01:00:04+00:00                                          41.299999          \n",
       "\n",
       "                           ProzessData_ActData_AB1_Temperature_DP1_WaterHeatingStage  \\\n",
       "2023-03-16 01:00:00+00:00                                          42.000000           \n",
       "2023-03-16 01:00:01+00:00                                          42.099998           \n",
       "2023-03-16 01:00:02+00:00                                          42.099998           \n",
       "2023-03-16 01:00:03+00:00                                          42.099998           \n",
       "2023-03-16 01:00:04+00:00                                          42.099998           \n",
       "\n",
       "                           ProzessData_ActData_AB1_Temperature_DQ1_MassCoolingStage  \\\n",
       "2023-03-16 01:00:00+00:00                                          41.599998          \n",
       "2023-03-16 01:00:01+00:00                                          41.599998          \n",
       "2023-03-16 01:00:02+00:00                                          41.599998          \n",
       "2023-03-16 01:00:03+00:00                                          41.599998          \n",
       "2023-03-16 01:00:04+00:00                                          41.599998          \n",
       "\n",
       "                           ProzessData_ActData_AB1_Temperature_DQ1_WaterCoolingStage  \\\n",
       "2023-03-16 01:00:00+00:00                                               42.0           \n",
       "2023-03-16 01:00:01+00:00                                               42.0           \n",
       "2023-03-16 01:00:02+00:00                                               42.0           \n",
       "2023-03-16 01:00:03+00:00                                               42.0           \n",
       "2023-03-16 01:00:04+00:00                                               42.0           \n",
       "\n",
       "                           ProzessData_ActData_AB1_Temperature_DR1_WaterMixingStage  \\\n",
       "2023-03-16 01:00:00+00:00                                               42.0          \n",
       "2023-03-16 01:00:01+00:00                                               42.0          \n",
       "2023-03-16 01:00:02+00:00                                               42.0          \n",
       "2023-03-16 01:00:03+00:00                                               42.0          \n",
       "2023-03-16 01:00:04+00:00                                               42.0          \n",
       "\n",
       "                           ProzessData_ActData_AB1_Temperature_DS1_WaterPipe  \\\n",
       "2023-03-16 01:00:00+00:00                                          41.849998   \n",
       "2023-03-16 01:00:01+00:00                                          41.849998   \n",
       "2023-03-16 01:00:02+00:00                                          41.849998   \n",
       "2023-03-16 01:00:03+00:00                                          41.849998   \n",
       "2023-03-16 01:00:04+00:00                                          41.849998   \n",
       "\n",
       "                           ProzessData_ActData_AB1_Temperature_DU1_WaterTank  \\\n",
       "2023-03-16 01:00:00+00:00                                          42.000000   \n",
       "2023-03-16 01:00:01+00:00                                          41.900002   \n",
       "2023-03-16 01:00:02+00:00                                          41.900002   \n",
       "2023-03-16 01:00:03+00:00                                          41.900002   \n",
       "2023-03-16 01:00:04+00:00                                          41.900002   \n",
       "\n",
       "                           ProzessData_ActData_AB1_Temperature_DX1_MassInfeed  \\\n",
       "2023-03-16 01:00:00+00:00                                          41.900002    \n",
       "2023-03-16 01:00:01+00:00                                          41.900002    \n",
       "2023-03-16 01:00:02+00:00                                          41.900002    \n",
       "2023-03-16 01:00:03+00:00                                          41.900002    \n",
       "2023-03-16 01:00:04+00:00                                          41.900002    \n",
       "\n",
       "                           hour  minute  day_time  night_time  \n",
       "2023-03-16 01:00:00+00:00     1       0         0           1  \n",
       "2023-03-16 01:00:01+00:00     1       0         0           1  \n",
       "2023-03-16 01:00:02+00:00     1       0         0           1  \n",
       "2023-03-16 01:00:03+00:00     1       0         0           1  \n",
       "2023-03-16 01:00:04+00:00     1       0         0           1  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "test_x = pd.read_parquet(\"../../data/preprocessed/thursdays.pq\")\n",
    "test_y = pd.read_parquet(\"../../data/preprocessed/thursdays_y.pq\")\n",
    "\n",
    "X = pd.read_parquet('../../data/preprocessed/full_data.pq')\n",
    "y = pd.read_parquet('../../data/preprocessed/full_data_y.pq')\n",
    "\n",
    "X1_train = pd.read_parquet('../../data/preprocessed/holdout_1.pq')\n",
    "X1_test = pd.read_parquet('../../data/preprocessed/thursdays.pq')\n",
    "y1_train = pd.read_parquet('../../data/preprocessed/holdout_1_y.pq')\n",
    "y1_test = pd.read_parquet('../../data/preprocessed/thursdays_y.pq')\n",
    "\n",
    "X2_train = pd.read_parquet('../../data/preprocessed/holdout_2.pq')\n",
    "X2_test = pd.read_parquet('../../data/preprocessed/tuesdays.pq')\n",
    "y2_train = pd.read_parquet('../../data/preprocessed/holdout_2_y.pq')\n",
    "y2_test = pd.read_parquet('../../data/preprocessed/tuesdays_y.pq')\n",
    "\n",
    "X3_train = pd.read_parquet('../../data/preprocessed/holdout_3.pq')\n",
    "X3_test = pd.read_parquet('../../data/preprocessed/wednesdays.pq')\n",
    "y3_train = pd.read_parquet('../../data/preprocessed/holdout_3_y.pq')\n",
    "y3_test = pd.read_parquet('../../data/preprocessed/wednesdays_y.pq')\n",
    "\n",
    "print(f\"X1 Train Shapes [{X1_train.shape} / {y1_train.shape}]\")\n",
    "print(f\"X1 Test Shapes [{X1_test.shape} / {y1_test.shape}]\")\n",
    "print(f\"X2 Train Shapes [{X2_train.shape} / {y2_train.shape}]\")\n",
    "print(f\"X2 Test Shapes [{X2_test.shape} / {y2_test.shape}]\")\n",
    "print(X1_train.columns)\n",
    "X1_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "478807"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/OWL_Factory_Hackathon/notebooks/2_modelling/lstm_philip.ipynb Zelle 5\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bfictional-lamp-g66rv647gwvfpw6/workspaces/OWL_Factory_Hackathon/notebooks/2_modelling/lstm_philip.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=64'>65</a>\u001b[0m list2 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(list2)\u001b[39m.\u001b[39mflatten()\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bfictional-lamp-g66rv647gwvfpw6/workspaces/OWL_Factory_Hackathon/notebooks/2_modelling/lstm_philip.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=65'>66</a>\u001b[0m abweichung \u001b[39m=\u001b[39m []\n\u001b[0;32m---> <a href='vscode-notebook-cell://codespaces%2Bfictional-lamp-g66rv647gwvfpw6/workspaces/OWL_Factory_Hackathon/notebooks/2_modelling/lstm_philip.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=66'>67</a>\u001b[0m abweichung \u001b[39m=\u001b[39m [\u001b[39mabs\u001b[39m(a \u001b[39m-\u001b[39m b[\u001b[39m0\u001b[39m]) \u001b[39mfor\u001b[39;00m a, b \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(y_pred, y_test)]\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bfictional-lamp-g66rv647gwvfpw6/workspaces/OWL_Factory_Hackathon/notebooks/2_modelling/lstm_philip.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=68'>69</a>\u001b[0m points \u001b[39m=\u001b[39m []\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bfictional-lamp-g66rv647gwvfpw6/workspaces/OWL_Factory_Hackathon/notebooks/2_modelling/lstm_philip.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=69'>70</a>\u001b[0m \u001b[39mfor\u001b[39;00m diff \u001b[39min\u001b[39;00m abweichung:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "target_column = 'ProzessData_ActData_AB1_Temperature_DR1_MassMixingStage'\n",
    "\n",
    "# Normalize features in train_x (excluding the timestamp column)\n",
    "scaler_x = MinMaxScaler()\n",
    "train_x_scaled = scaler_x.fit_transform(train_x.iloc[:, 1:])  # Adjust if the first column isn't the timestamp\n",
    "\n",
    "# Normalize the target column in train_y\n",
    "scaler_y = MinMaxScaler()\n",
    "train_y_scaled = scaler_y.fit_transform(train_y[[target_column]])\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "train_x_tensor = torch.tensor(train_x_scaled).float().unsqueeze(1)  # Add time step dimension\n",
    "train_y_tensor = torch.tensor(train_y_scaled).float()\n",
    "\n",
    "# DataLoader\n",
    "train_dataset = TensorDataset(train_x_tensor, train_y_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# LSTM model\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        out = self.dropout(lstm_out[:, -1, :])\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "# Model initialization\n",
    "input_dim = train_x_tensor.shape[2]  # Number of features\n",
    "hidden_dim = 50  # Example value\n",
    "output_dim = train_y_tensor.shape[1]  # Should be 1 as we're predicting a single target\n",
    "\n",
    "model = LSTMModel(input_dim, hidden_dim, output_dim).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "\n",
    "num_epochs = 30\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    total_mae = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Calculate loss (MSE)\n",
    "        loss = criterion(outputs, labels)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Calculate MAE\n",
    "        #print(type(F.l1_loss(outputs, labels, reduction='sum').item()))\n",
    "        list1 = outputs.tolist()\n",
    "        list2 = labels.tolist()\n",
    "        list1 = np.array(list1).flatten()\n",
    "        list2 = np.array(list2).flatten()\n",
    "        abweichung = []\n",
    "        for a, b in zip(list1, list2):\n",
    "            \n",
    "            abweichung.append(abs(a - b))    # Give points\n",
    "        points = []\n",
    "        for diff in abweichung:\n",
    "            if diff < 0.05:\n",
    "                points.append(1.0)\n",
    "            elif 0.05 <= diff < 0.1:\n",
    "                points.append(0.5)\n",
    "            elif 0.1 <= diff < 0.5:\n",
    "                points.append(0.25)\n",
    "            else:\n",
    "                points.append(0) \n",
    "\n",
    "        list1 = points\n",
    "\n",
    "        points2 = [] \n",
    "        consecutive_count =0      \n",
    "        for i in range(0, len(list1)):\n",
    "            \n",
    "            if list1[i] >=0.5 and consecutive_count == 0 :\n",
    "\n",
    "                points2.append (1)\n",
    "\n",
    "            elif list1[i] >=0.5 and consecutive_count != 0:\n",
    "\n",
    "                if consecutive_count == 1:\n",
    "                    points2.append (.5)\n",
    "                    points2.append(1)\n",
    "        \n",
    "                elif 2 <= consecutive_count <= 10:\n",
    "                    points2.extend([0.25] * consecutive_count)\n",
    "                    points2.append(1)\n",
    "                else:\n",
    "                    points2.extend([0] * consecutive_count)\n",
    "                    points2.append(1)\n",
    "\n",
    "                consecutive_count = 0# Reset consecutive count\n",
    "\n",
    "            else:\n",
    "                consecutive_count+=1\n",
    "\n",
    "        \n",
    "        if consecutive_count == 1:\n",
    "            points2.append (.5)\n",
    "        elif 2 <= consecutive_count <= 0.01:\n",
    "            points2.extend([0.25] * consecutive_count)\n",
    "        else:\n",
    "            points2.extend([0] * consecutive_count)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        total = sum(points)+sum(points2) \n",
    "        maxpoint = len(points)*2\n",
    "\n",
    "        #print(\" Punkte aus abweichungslist:\", sum(points), \"Punkte aus Zeitabweichung:\", sum(points2), \"max Punkte:\",len(points))\n",
    "\n",
    "        #print(total/maxpoint)\n",
    "        \n",
    "        mae = ((maxpoint/total)-1)*100\n",
    "        total_mae += mae\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Average loss and MAE over the epoch\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    avg_mae = total_mae / len(train_loader.dataset)\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}, MAE: {avg_mae:.4f}')\n",
    "    print(total/maxpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(X_test, y_test, y_pred, pca=False, examples=True):\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    print(f\"MAE: {mae}\")\n",
    "    \n",
    "    \n",
    "\n",
    "    # Calculate absolute differences element-wise\n",
    "    abweichung = [abs(a - b[0]) for a, b in zip(y_pred, y_test)]\n",
    "\n",
    "    points = []\n",
    "    for diff in abweichung:\n",
    "        if diff < 0.05:\n",
    "            points.append(1.0)\n",
    "        elif 0.05 <= diff < 0.1:\n",
    "            points.append(0.5)\n",
    "        elif 0.1 <= diff < 0.5:\n",
    "            points.append(0.25)\n",
    "        else:\n",
    "            points.append(0)\n",
    "\n",
    "    list1 = points\n",
    "\n",
    "    points2 = []\n",
    "    consecutive_count = 0\n",
    "    for i in range(0, len(list1)):\n",
    "        if list1[i] >= 0.5 and consecutive_count == 0:\n",
    "            points2.append(1)\n",
    "        elif list1[i] >= 0.5 and consecutive_count != 0:\n",
    "            if consecutive_count == 1:\n",
    "                points2.append(0.5)\n",
    "                points2.append(1)\n",
    "            elif 2 <= consecutive_count <= 10:\n",
    "                points2.extend([0.25] * consecutive_count)\n",
    "                points2.append(1)\n",
    "            else:\n",
    "                points2.extend([0] * consecutive_count)\n",
    "                points2.append(1)\n",
    "            consecutive_count = 0  # Reset consecutive count\n",
    "        else:\n",
    "            consecutive_count += 1\n",
    "\n",
    "    if consecutive_count == 1:\n",
    "        points2.append(0.5)\n",
    "    elif 2 <= consecutive_count <= 10:\n",
    "        points2.extend([0.25] * consecutive_count)\n",
    "    else:\n",
    "        points2.extend([0] * consecutive_count)\n",
    "\n",
    "    total = sum(points) + sum(points2)\n",
    "    maxpoint = len(points) * 2\n",
    "\n",
    "    print(\"Punkte aus abweichungslist:\", sum(points), \"Punkte aus Zeitabweichung:\", sum(points2), \"max Punkte:\", len(points))\n",
    "\n",
    "    print(total / maxpoint)\n",
    "\n",
    "    if not pca and examples:\n",
    "        # Print some example predictions\n",
    "        example_indices = [0, 1, 2, 3, 4]\n",
    "        for i in example_indices:\n",
    "            print(f\"Index {i}: | Actual y: {y_test[i][0]} | Predicted y: {y_pred[i]}\")\n",
    "\n",
    "# Call the evaluation function\n",
    "\n",
    "\n",
    "\n",
    "# Utility Functions\n",
    "def add_time_features(df):\n",
    "    df['hour'] = df.index.hour\n",
    "    df['minute'] = df.index.minute\n",
    "    daytime_arr = []\n",
    "    for idx in df.index:\n",
    "        if df.loc[idx, \"hour\"] >= 6 and df.loc[idx, \"hour\"] <= 18:\n",
    "            daytime_arr.append(1)\n",
    "        else:\n",
    "            daytime_arr.append(0)\n",
    "\n",
    "    df['day_time'] = daytime_arr\n",
    "    df['night_time'] = 1 - df['day_time']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mae:5.38235\tvalidation-mae:5.53709\n",
      "[1]\ttrain-mae:4.84427\tvalidation-mae:4.98382\n",
      "[2]\ttrain-mae:4.36000\tvalidation-mae:4.48548\n",
      "[3]\ttrain-mae:3.92415\tvalidation-mae:4.03757\n",
      "[4]\ttrain-mae:3.53188\tvalidation-mae:3.63411\n",
      "[5]\ttrain-mae:3.17882\tvalidation-mae:3.28048\n",
      "[6]\ttrain-mae:2.86107\tvalidation-mae:2.95330\n",
      "[7]\ttrain-mae:2.57506\tvalidation-mae:2.65869\n",
      "[8]\ttrain-mae:2.31768\tvalidation-mae:2.39366\n",
      "[9]\ttrain-mae:2.08603\tvalidation-mae:2.15519\n",
      "[10]\ttrain-mae:1.87753\tvalidation-mae:1.94015\n",
      "[11]\ttrain-mae:1.68988\tvalidation-mae:1.74689\n",
      "[12]\ttrain-mae:1.52099\tvalidation-mae:1.57283\n",
      "[13]\ttrain-mae:1.36900\tvalidation-mae:1.41626\n",
      "[14]\ttrain-mae:1.23222\tvalidation-mae:1.27529\n",
      "[15]\ttrain-mae:1.10912\tvalidation-mae:1.14848\n",
      "[16]\ttrain-mae:0.99831\tvalidation-mae:1.03465\n",
      "[17]\ttrain-mae:0.89858\tvalidation-mae:0.93218\n",
      "[18]\ttrain-mae:0.80884\tvalidation-mae:0.83949\n",
      "[19]\ttrain-mae:0.72807\tvalidation-mae:0.75621\n",
      "[20]\ttrain-mae:0.65539\tvalidation-mae:0.68132\n",
      "[21]\ttrain-mae:0.58997\tvalidation-mae:0.61414\n",
      "[22]\ttrain-mae:0.53111\tvalidation-mae:0.55302\n",
      "[23]\ttrain-mae:0.47815\tvalidation-mae:0.49810\n",
      "[24]\ttrain-mae:0.43051\tvalidation-mae:0.44889\n",
      "[25]\ttrain-mae:0.38766\tvalidation-mae:0.40493\n",
      "[26]\ttrain-mae:0.34912\tvalidation-mae:0.36526\n",
      "[27]\ttrain-mae:0.31443\tvalidation-mae:0.32966\n",
      "[28]\ttrain-mae:0.28323\tvalidation-mae:0.29714\n",
      "[29]\ttrain-mae:0.25520\tvalidation-mae:0.26818\n",
      "[30]\ttrain-mae:0.22996\tvalidation-mae:0.24194\n",
      "[31]\ttrain-mae:0.20726\tvalidation-mae:0.21813\n",
      "[32]\ttrain-mae:0.18685\tvalidation-mae:0.19663\n",
      "[33]\ttrain-mae:0.16852\tvalidation-mae:0.17762\n",
      "[34]\ttrain-mae:0.15205\tvalidation-mae:0.16085\n",
      "[35]\ttrain-mae:0.13730\tvalidation-mae:0.14566\n",
      "[36]\ttrain-mae:0.12406\tvalidation-mae:0.13230\n",
      "[37]\ttrain-mae:0.11217\tvalidation-mae:0.12024\n",
      "[38]\ttrain-mae:0.10150\tvalidation-mae:0.10964\n",
      "[39]\ttrain-mae:0.09196\tvalidation-mae:0.10005\n",
      "[40]\ttrain-mae:0.08344\tvalidation-mae:0.09169\n",
      "[41]\ttrain-mae:0.07625\tvalidation-mae:0.08395\n",
      "[42]\ttrain-mae:0.07005\tvalidation-mae:0.07725\n",
      "[43]\ttrain-mae:0.06469\tvalidation-mae:0.07159\n",
      "[44]\ttrain-mae:0.05986\tvalidation-mae:0.06680\n",
      "[45]\ttrain-mae:0.05599\tvalidation-mae:0.06282\n",
      "[46]\ttrain-mae:0.05241\tvalidation-mae:0.05938\n",
      "[47]\ttrain-mae:0.04919\tvalidation-mae:0.05606\n",
      "[48]\ttrain-mae:0.04646\tvalidation-mae:0.05309\n",
      "[49]\ttrain-mae:0.04402\tvalidation-mae:0.05038\n",
      "[50]\ttrain-mae:0.04178\tvalidation-mae:0.04805\n",
      "[51]\ttrain-mae:0.03982\tvalidation-mae:0.04598\n",
      "[52]\ttrain-mae:0.03785\tvalidation-mae:0.04417\n",
      "[53]\ttrain-mae:0.03630\tvalidation-mae:0.04251\n",
      "[54]\ttrain-mae:0.03463\tvalidation-mae:0.04123\n",
      "[55]\ttrain-mae:0.03335\tvalidation-mae:0.03985\n",
      "[56]\ttrain-mae:0.03203\tvalidation-mae:0.03863\n",
      "[57]\ttrain-mae:0.03088\tvalidation-mae:0.03787\n",
      "[58]\ttrain-mae:0.02999\tvalidation-mae:0.03694\n",
      "[59]\ttrain-mae:0.02914\tvalidation-mae:0.03644\n",
      "[60]\ttrain-mae:0.02846\tvalidation-mae:0.03640\n",
      "[61]\ttrain-mae:0.02769\tvalidation-mae:0.03588\n",
      "[62]\ttrain-mae:0.02707\tvalidation-mae:0.03546\n",
      "[63]\ttrain-mae:0.02647\tvalidation-mae:0.03498\n",
      "[64]\ttrain-mae:0.02605\tvalidation-mae:0.03483\n",
      "[65]\ttrain-mae:0.02563\tvalidation-mae:0.03446\n",
      "[66]\ttrain-mae:0.02530\tvalidation-mae:0.03474\n",
      "[67]\ttrain-mae:0.02501\tvalidation-mae:0.03449\n",
      "[68]\ttrain-mae:0.02462\tvalidation-mae:0.03416\n",
      "[69]\ttrain-mae:0.02438\tvalidation-mae:0.03410\n",
      "[70]\ttrain-mae:0.02412\tvalidation-mae:0.03409\n",
      "[71]\ttrain-mae:0.02395\tvalidation-mae:0.03397\n",
      "[72]\ttrain-mae:0.02361\tvalidation-mae:0.03425\n",
      "[73]\ttrain-mae:0.02348\tvalidation-mae:0.03415\n",
      "[74]\ttrain-mae:0.02335\tvalidation-mae:0.03406\n",
      "[75]\ttrain-mae:0.02324\tvalidation-mae:0.03398\n",
      "[76]\ttrain-mae:0.02311\tvalidation-mae:0.03390\n",
      "[77]\ttrain-mae:0.02302\tvalidation-mae:0.03384\n",
      "[78]\ttrain-mae:0.02293\tvalidation-mae:0.03379\n",
      "[79]\ttrain-mae:0.02262\tvalidation-mae:0.03398\n",
      "[80]\ttrain-mae:0.02259\tvalidation-mae:0.03396\n",
      "[81]\ttrain-mae:0.02243\tvalidation-mae:0.03418\n",
      "[82]\ttrain-mae:0.02238\tvalidation-mae:0.03415\n",
      "[83]\ttrain-mae:0.02237\tvalidation-mae:0.03415\n",
      "[84]\ttrain-mae:0.02237\tvalidation-mae:0.03415\n",
      "[85]\ttrain-mae:0.02237\tvalidation-mae:0.03415\n",
      "[86]\ttrain-mae:0.02237\tvalidation-mae:0.03415\n",
      "[87]\ttrain-mae:0.02237\tvalidation-mae:0.03415\n"
     ]
    }
   ],
   "source": [
    "# Convert the data into DMatrix format\n",
    "dtrain = xgb.DMatrix(X1_train, label=y1_train)\n",
    "dtest = xgb.DMatrix(X1_test, label=y1_test)\n",
    "\n",
    "\n",
    "\n",
    "# Set the parameters for XGBoost\n",
    "params = {\n",
    "    'objective': 'reg:squarederror',\n",
    "    'eval_metric': 'mae',\n",
    "    \n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': 5,  # Choose one value, not a list\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'min_child_weight': 1,  # Choose one value, not a list\n",
    "    'gamma': 1,\n",
    "    'alpha': 10\n",
    "    \n",
    "}\n",
    "\n",
    "# Train the XGBoost model with early stopping\n",
    "num_rounds = 1000\n",
    "evals = [(dtrain, 'train'), (dtest, 'validation')]\n",
    "xgb_model = xgb.train(params, dtrain, num_boost_round=num_rounds, evals=evals, early_stopping_rounds=10, verbose_eval=True)\n",
    "\n",
    "\n",
    "\n",
    "# Save the trained model\n",
    "xgb_model.save_model('../../data/modeltestphilip.json')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [06:27:17] WARNING: /workspace/src/c_api/c_api.cc:1240: Saving into deprecated binary model format, please consider using `json` or `ubj`. Model format will default to JSON in XGBoost 2.2 if not specified.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MAE: 0.022771084222007087\n",
      "Punkte aus abweichungslist: 188994.5 Punkte aus Zeitabweichung: 201586.0 max Punkte: 205203\n",
      "0.9516929577052967\n",
      "Index 0: | Actual y: 41.5 | Predicted y: 41.51360321044922\n",
      "Index 1: | Actual y: 41.5 | Predicted y: 41.51360321044922\n",
      "Index 2: | Actual y: 41.5 | Predicted y: 41.51360321044922\n",
      "Index 3: | Actual y: 41.5 | Predicted y: 41.51360321044922\n",
      "Index 4: | Actual y: 41.5 | Predicted y: 41.51360321044922\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dtrain2 = xgb.DMatrix(X2_train, label=y2_train)\n",
    "#dtest2 = xgb.DMatrix(X2_test, label=y2_test)\n",
    "\n",
    "dtrain3 = xgb.DMatrix(X3_train, label=y3_train)\n",
    "dtest3 = xgb.DMatrix(X3_test, label=y3_test)\n",
    "\n",
    "existing_model = xgb.Booster(model_file='../../data/modeltestphilip.json')\n",
    "params = {\n",
    "    'objective': 'reg:squarederror',\n",
    "    'eval_metric': 'mae',\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': 3,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'min_child_weight': 1,\n",
    "    'gamma': 1,\n",
    "    'alpha': 0.1\n",
    "}\n",
    "\n",
    "# Continue training the existing model on new data\n",
    "num_boost_round = 300\n",
    "xgb_model = xgb.train(params, dtrain2, num_boost_round=num_boost_round, xgb_model=existing_model)\n",
    "num_boost_round = 300\n",
    "xgb_model = xgb.train(params, dtrain3, num_boost_round=num_boost_round, xgb_model=existing_model)\n",
    "\n",
    "# Save the updated model\n",
    "xgb_model.save_model('../../data/modeltestxgb.model')\n",
    "\n",
    "# Make predictions on the validation data\n",
    "y_pred_val = xgb_model.predict(dtest3)\n",
    "\n",
    "# Convert NumPy array to Python list\n",
    "y_pred_val_list = y_pred_val.tolist()\n",
    "y_pred_val_list = [float(d) for d in y_pred_val_list]\n",
    "print(type(y_pred_val_list))\n",
    "print(type(y3_test))\n",
    "\n",
    "y3_test_list = y3_test.values.tolist()\n",
    "\n",
    "\n",
    "# Now you can use X2_train and y_pred_val_list in your further processing or evaluation\n",
    "\n",
    "# Assuming you have an evaluation function named 'evaluation'\n",
    "evaluation(X3_train, y3_test_list, y_pred_val_list)\n",
    "xgb_model.save_model('../../data/modeltestphilip.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/OWL_Factory_Hackathon/notebooks/2_modelling/lstm_philip.ipynb Zelle 8\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bfictional-lamp-g66rv647gwvfpw6/workspaces/OWL_Factory_Hackathon/notebooks/2_modelling/lstm_philip.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=37'>38</a>\u001b[0m target_column \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mProzessData_ActData_AB1_Temperature_DR1_MassMixingStage\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bfictional-lamp-g66rv647gwvfpw6/workspaces/OWL_Factory_Hackathon/notebooks/2_modelling/lstm_philip.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39m# Preprocess data\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://codespaces%2Bfictional-lamp-g66rv647gwvfpw6/workspaces/OWL_Factory_Hackathon/notebooks/2_modelling/lstm_philip.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=40'>41</a>\u001b[0m train_x_tensor, train_y_tensor \u001b[39m=\u001b[39m preprocess_data(train_x, train_y, test_x, test_y, target_column)\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bfictional-lamp-g66rv647gwvfpw6/workspaces/OWL_Factory_Hackathon/notebooks/2_modelling/lstm_philip.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39m# Train XGBoost model\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bfictional-lamp-g66rv647gwvfpw6/workspaces/OWL_Factory_Hackathon/notebooks/2_modelling/lstm_philip.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=43'>44</a>\u001b[0m xgboost_model \u001b[39m=\u001b[39m train_xgboost_model(train_x_tensor, train_y_tensor)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_x' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def preprocess_data(train_x, train_y, test_x, test_y, target_column):\n",
    "    # Normalize features in train_x (excluding the timestamp column)\n",
    "    scaler_x = MinMaxScaler()\n",
    "    train_x_scaled = scaler_x.fit_transform(train_x.iloc[:, 1:])  # Adjust if the first column isn't the timestamp\n",
    "\n",
    "    # Flatten time series sequences into feature vectors\n",
    "    train_x_flattened = train_x_scaled.reshape((len(train_x), -1))\n",
    "\n",
    "    # Normalize the target column in train_y\n",
    "    scaler_y = MinMaxScaler()\n",
    "    train_y_scaled = scaler_y.fit_transform(train_y[[target_column]])\n",
    "\n",
    "    # Convert to NumPy arrays\n",
    "    train_x_tensor = np.float32(train_x_flattened)  # No need to add a time step dimension\n",
    "    train_y_tensor = np.float32(train_y_scaled)\n",
    "\n",
    "    return train_x_tensor, train_y_tensor\n",
    "\n",
    "\n",
    "def train_xgboost_model(x_train, y_train):\n",
    "    # XGBoost Model\n",
    "    xgboost_model = XGBRegressor(objective='reg:squarederror')\n",
    "    xgboost_model.fit(x_train, y_train)\n",
    "\n",
    "    return xgboost_model\n",
    "\n",
    "def evaluate_model(model, x_test, y_test):\n",
    "    # Predictions on the test set\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    # Calculate Mean Absolute Error (MAE)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    \n",
    "    return mae\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Target column\n",
    "    target_column = 'ProzessData_ActData_AB1_Temperature_DR1_MassMixingStage'\n",
    "\n",
    "    # Preprocess data\n",
    "    train_x_tensor, train_y_tensor = preprocess_data(train_x, train_y, test_x, test_y, target_column)\n",
    "\n",
    "    # Train XGBoost model\n",
    "    xgboost_model = train_xgboost_model(train_x_tensor, train_y_tensor)\n",
    "\n",
    "    # Evaluate the XGBoost model\n",
    "    x_test_tensor = np.float32(test_x.iloc[:, 1:].values[:, :, None])\n",
    "    y_test_xgboost = test_y[target_column].values\n",
    "    shape = x_test_tensor.shape\n",
    "\n",
    "    x_test_tensor = x_test_tensor.reshape((shape[0], shape[1]))\n",
    "    print(\"Shape of x_test_tensor:\", x_test_tensor.shape)\n",
    "    mae_xgboost = evaluate_model(xgboost_model, x_test_tensor, y_test_xgboost)\n",
    "\n",
    "    print(f'XGBoost MAE: {mae_xgboost:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Assuming your model is named 'model'\n",
    "torch.save(model, '../../models/lstm_philip2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pickle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/OWL_Factory_Hackathon/notebooks/2_modelling/lstm_philip.ipynb Zelle 6\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bfictional-lamp-g66rv647gwvfpw6/workspaces/OWL_Factory_Hackathon/notebooks/2_modelling/lstm_philip.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m../../models/lstm_philip.pkl\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m file:\n\u001b[0;32m----> <a href='vscode-notebook-cell://codespaces%2Bfictional-lamp-g66rv647gwvfpw6/workspaces/OWL_Factory_Hackathon/notebooks/2_modelling/lstm_philip.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     pickle\u001b[39m.\u001b[39mdump(model, file)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pickle' is not defined"
     ]
    }
   ],
   "source": [
    "with open('../../models/lstm_philip2.pkl', 'wb') as file:\n",
    "    pickle.dump(model, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jhn_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "7ba48d1dfc31994510d1202d5cc1ad7c5341fe2fe772e21645b10ef4af5c8f4c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
