{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pickle\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = pd.read_parquet(\"../../data/preprocessed/holdout_1.pq\") # , engine='pyarrow'\n",
    "train_y = pd.read_parquet(\"../../data/preprocessed/holdout_1_y.pq\")\n",
    "test_x = pd.read_parquet(\"../../data/preprocessed/thursdays.pq\")\n",
    "test_y = pd.read_parquet(\"../../data/preprocessed/thursdays_y.pq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "478807"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Module [ModuleList] is missing the required \"forward\" function",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/OWL_Factory_Hackathon/notebooks/2_modelling/lstm_philip.ipynb Zelle 5\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bfictional-lamp-g66rv647gwvfpw6/workspaces/OWL_Factory_Hackathon/notebooks/2_modelling/lstm_philip.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=51'>52</a>\u001b[0m inputs, labels \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39mto(device), labels\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bfictional-lamp-g66rv647gwvfpw6/workspaces/OWL_Factory_Hackathon/notebooks/2_modelling/lstm_philip.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=52'>53</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell://codespaces%2Bfictional-lamp-g66rv647gwvfpw6/workspaces/OWL_Factory_Hackathon/notebooks/2_modelling/lstm_philip.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=53'>54</a>\u001b[0m outputs \u001b[39m=\u001b[39m model(inputs)\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bfictional-lamp-g66rv647gwvfpw6/workspaces/OWL_Factory_Hackathon/notebooks/2_modelling/lstm_philip.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=55'>56</a>\u001b[0m \u001b[39m# Calculate loss (MSE)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bfictional-lamp-g66rv647gwvfpw6/workspaces/OWL_Factory_Hackathon/notebooks/2_modelling/lstm_philip.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=56'>57</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, labels)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32m/workspaces/OWL_Factory_Hackathon/notebooks/2_modelling/lstm_philip.ipynb Zelle 5\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bfictional-lamp-g66rv647gwvfpw6/workspaces/OWL_Factory_Hackathon/notebooks/2_modelling/lstm_philip.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bfictional-lamp-g66rv647gwvfpw6/workspaces/OWL_Factory_Hackathon/notebooks/2_modelling/lstm_philip.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m     lstm_out, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlstm(x)\n\u001b[0;32m---> <a href='vscode-notebook-cell://codespaces%2Bfictional-lamp-g66rv647gwvfpw6/workspaces/OWL_Factory_Hackathon/notebooks/2_modelling/lstm_philip.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout(lstm_out[:, \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, :])\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bfictional-lamp-g66rv647gwvfpw6/workspaces/OWL_Factory_Hackathon/notebooks/2_modelling/lstm_philip.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc(out)\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bfictional-lamp-g66rv647gwvfpw6/workspaces/OWL_Factory_Hackathon/notebooks/2_modelling/lstm_philip.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:372\u001b[0m, in \u001b[0;36m_forward_unimplemented\u001b[0;34m(self, *input)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_forward_unimplemented\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39minput\u001b[39m: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    362\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Defines the computation performed at every call.\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \n\u001b[1;32m    364\u001b[0m \u001b[39m    Should be overridden by all subclasses.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[39m        registered hooks while the latter silently ignores them.\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 372\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mModule [\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m] is missing the required \u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39mforward\u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39m function\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Module [ModuleList] is missing the required \"forward\" function"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "target_column = 'ProzessData_ActData_AB1_Temperature_DR1_MassMixingStage'\n",
    "\n",
    "# Normalize features in train_x (excluding the timestamp column)\n",
    "scaler_x = MinMaxScaler()\n",
    "train_x_scaled = scaler_x.fit_transform(train_x.iloc[:, 1:])  # Adjust if the first column isn't the timestamp\n",
    "\n",
    "# Normalize the target column in train_y\n",
    "scaler_y = MinMaxScaler()\n",
    "train_y_scaled = scaler_y.fit_transform(train_y[[target_column]])\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "train_x_tensor = torch.tensor(train_x_scaled).float().unsqueeze(1)  # Add time step dimension\n",
    "train_y_tensor = torch.tensor(train_y_scaled).float()\n",
    "\n",
    "# DataLoader\n",
    "train_dataset = TensorDataset(train_x_tensor, train_y_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# LSTM model\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
    "        self.dropout = nn.ModuleList([nn.Dropout(0.2)])\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        out = self.dropout(lstm_out[:, -1, :])\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "# Model initialization\n",
    "input_dim = train_x_tensor.shape[2]  # Number of features\n",
    "hidden_dim = 50  # Example value\n",
    "output_dim = train_y_tensor.shape[1]  # Should be 1 as we're predicting a single target\n",
    "\n",
    "model = LSTMModel(input_dim, hidden_dim, output_dim).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "\n",
    "num_epochs = 30\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    total_mae = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Calculate loss (MSE)\n",
    "        loss = criterion(outputs, labels)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Calculate MAE\n",
    "        #print(type(F.l1_loss(outputs, labels, reduction='sum').item()))\n",
    "        list1 = outputs.tolist()\n",
    "        list2 = labels.tolist()\n",
    "        list1 = np.array(list1).flatten()\n",
    "        list2 = np.array(list2).flatten()\n",
    "        abweichung = []\n",
    "        for a, b in zip(list1, list2):\n",
    "            \n",
    "            abweichung.append(abs(a - b))    # Give points\n",
    "        points = []\n",
    "        for diff in abweichung:\n",
    "            if diff < 0.05:\n",
    "                points.append(1.0)\n",
    "            elif 0.05 <= diff < 0.1:\n",
    "                points.append(0.5)\n",
    "            elif 0.1 <= diff < 0.5:\n",
    "                points.append(0.25)\n",
    "            else:\n",
    "                points.append(0) \n",
    "\n",
    "        list1 = points\n",
    "\n",
    "        points2 = [] \n",
    "        consecutive_count =0      \n",
    "        for i in range(0, len(list1)):\n",
    "            \n",
    "            if list1[i] >=0.5 and consecutive_count == 0 :\n",
    "\n",
    "                points2.append (1)\n",
    "\n",
    "            elif list1[i] >=0.5 and consecutive_count != 0:\n",
    "\n",
    "                if consecutive_count == 1:\n",
    "                    points2.append (.5)\n",
    "                    points2.append(1)\n",
    "        \n",
    "                elif 2 <= consecutive_count <= 10:\n",
    "                    points2.extend([0.25] * consecutive_count)\n",
    "                    points2.append(1)\n",
    "                else:\n",
    "                    points2.extend([0] * consecutive_count)\n",
    "                    points2.append(1)\n",
    "\n",
    "                consecutive_count = 0# Reset consecutive count\n",
    "\n",
    "            else:\n",
    "                consecutive_count+=1\n",
    "\n",
    "        \n",
    "        if consecutive_count == 1:\n",
    "            points2.append (.5)\n",
    "        elif 2 <= consecutive_count <= 0.01:\n",
    "            points2.extend([0.25] * consecutive_count)\n",
    "        else:\n",
    "            points2.extend([0] * consecutive_count)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        total = sum(points)+sum(points2) \n",
    "        maxpoint = len(points)*2\n",
    "\n",
    "        #print(\" Punkte aus abweichungslist:\", sum(points), \"Punkte aus Zeitabweichung:\", sum(points2), \"max Punkte:\",len(points))\n",
    "\n",
    "        #print(total/maxpoint)\n",
    "        \n",
    "        mae = ((maxpoint/total)-1)*100\n",
    "        total_mae += mae\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Average loss and MAE over the epoch\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    avg_mae = total_mae / len(train_loader.dataset)\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}, MAE: {avg_mae:.4f}')\n",
    "    print(total/maxpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_test_tensor: (273604, 17, 1)\n"
     ]
    },
    {
     "ename": "XGBoostError",
     "evalue": "[01:37:29] /workspace/src/c_api/../data/array_interface.h:233: Check failed: i < D (2 vs. 2) : Only 2 dimensional array is valid.\nStack trace:\n  [bt] (0) /home/codespace/.python/current/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x15c2ca) [0x7f6a36ba22ca]\n  [bt] (1) /home/codespace/.python/current/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x19e9a3) [0x7f6a36be49a3]\n  [bt] (2) /home/codespace/.python/current/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x19fcaf) [0x7f6a36be5caf]\n  [bt] (3) /home/codespace/.python/current/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x413064) [0x7f6a36e59064]\n  [bt] (4) /home/codespace/.python/current/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(XGBoosterPredictFromDense+0x25c) [0x7f6a36bb3d7c]\n  [bt] (5) /lib/x86_64-linux-gnu/libffi.so.7(+0x6ff5) [0x7f6b43149ff5]\n  [bt] (6) /lib/x86_64-linux-gnu/libffi.so.7(+0x640a) [0x7f6b4314940a]\n  [bt] (7) /home/codespace/.python/current/lib/python3.10/lib-dynload/_ctypes.cpython-310-x86_64-linux-gnu.so(+0x12f51) [0x7f6b433eff51]\n  [bt] (8) /home/codespace/.python/current/lib/python3.10/lib-dynload/_ctypes.cpython-310-x86_64-linux-gnu.so(+0xca11) [0x7f6b433e9a11]\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/OWL_Factory_Hackathon/notebooks/2_modelling/lstm_philip.ipynb Zelle 6\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bfictional-lamp-g66rv647gwvfpw6/workspaces/OWL_Factory_Hackathon/notebooks/2_modelling/lstm_philip.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=46'>47</a>\u001b[0m y_test_xgboost \u001b[39m=\u001b[39m test_y[target_column]\u001b[39m.\u001b[39mvalues\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bfictional-lamp-g66rv647gwvfpw6/workspaces/OWL_Factory_Hackathon/notebooks/2_modelling/lstm_philip.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=47'>48</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mShape of x_test_tensor:\u001b[39m\u001b[39m\"\u001b[39m, x_test_tensor\u001b[39m.\u001b[39mshape)\n\u001b[0;32m---> <a href='vscode-notebook-cell://codespaces%2Bfictional-lamp-g66rv647gwvfpw6/workspaces/OWL_Factory_Hackathon/notebooks/2_modelling/lstm_philip.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=48'>49</a>\u001b[0m mae_xgboost \u001b[39m=\u001b[39m evaluate_model(xgboost_model, x_test_tensor, y_test_xgboost)\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bfictional-lamp-g66rv647gwvfpw6/workspaces/OWL_Factory_Hackathon/notebooks/2_modelling/lstm_philip.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=50'>51</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mXGBoost MAE: \u001b[39m\u001b[39m{\u001b[39;00mmae_xgboost\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32m/workspaces/OWL_Factory_Hackathon/notebooks/2_modelling/lstm_philip.ipynb Zelle 6\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bfictional-lamp-g66rv647gwvfpw6/workspaces/OWL_Factory_Hackathon/notebooks/2_modelling/lstm_philip.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mevaluate_model\u001b[39m(model, x_test, y_test):\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bfictional-lamp-g66rv647gwvfpw6/workspaces/OWL_Factory_Hackathon/notebooks/2_modelling/lstm_philip.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m     \u001b[39m# Predictions on the test set\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://codespaces%2Bfictional-lamp-g66rv647gwvfpw6/workspaces/OWL_Factory_Hackathon/notebooks/2_modelling/lstm_philip.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m     y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(x_test)\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bfictional-lamp-g66rv647gwvfpw6/workspaces/OWL_Factory_Hackathon/notebooks/2_modelling/lstm_philip.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m     \u001b[39m# Calculate Mean Absolute Error (MAE)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bfictional-lamp-g66rv647gwvfpw6/workspaces/OWL_Factory_Hackathon/notebooks/2_modelling/lstm_philip.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m     mae \u001b[39m=\u001b[39m mean_absolute_error(y_test, y_pred)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/xgboost/sklearn.py:1164\u001b[0m, in \u001b[0;36mXGBModel.predict\u001b[0;34m(self, X, output_margin, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[1;32m   1162\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_can_use_inplace_predict():\n\u001b[1;32m   1163\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1164\u001b[0m         predts \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_booster()\u001b[39m.\u001b[39;49minplace_predict(\n\u001b[1;32m   1165\u001b[0m             data\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m   1166\u001b[0m             iteration_range\u001b[39m=\u001b[39;49miteration_range,\n\u001b[1;32m   1167\u001b[0m             predict_type\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mmargin\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39mif\u001b[39;49;00m output_margin \u001b[39melse\u001b[39;49;00m \u001b[39m\"\u001b[39;49m\u001b[39mvalue\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1168\u001b[0m             missing\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmissing,\n\u001b[1;32m   1169\u001b[0m             base_margin\u001b[39m=\u001b[39;49mbase_margin,\n\u001b[1;32m   1170\u001b[0m             validate_features\u001b[39m=\u001b[39;49mvalidate_features,\n\u001b[1;32m   1171\u001b[0m         )\n\u001b[1;32m   1172\u001b[0m         \u001b[39mif\u001b[39;00m _is_cupy_array(predts):\n\u001b[1;32m   1173\u001b[0m             \u001b[39mimport\u001b[39;00m \u001b[39mcupy\u001b[39;00m  \u001b[39m# pylint: disable=import-error\u001b[39;00m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/xgboost/core.py:2436\u001b[0m, in \u001b[0;36mBooster.inplace_predict\u001b[0;34m(self, data, iteration_range, predict_type, missing, validate_features, base_margin, strict_shape)\u001b[0m\n\u001b[1;32m   2433\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m _ensure_np_dtype\n\u001b[1;32m   2435\u001b[0m     data, _ \u001b[39m=\u001b[39m _ensure_np_dtype(data, data\u001b[39m.\u001b[39mdtype)\n\u001b[0;32m-> 2436\u001b[0m     _check_call(\n\u001b[1;32m   2437\u001b[0m         _LIB\u001b[39m.\u001b[39;49mXGBoosterPredictFromDense(\n\u001b[1;32m   2438\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle,\n\u001b[1;32m   2439\u001b[0m             _array_interface(data),\n\u001b[1;32m   2440\u001b[0m             args,\n\u001b[1;32m   2441\u001b[0m             p_handle,\n\u001b[1;32m   2442\u001b[0m             ctypes\u001b[39m.\u001b[39;49mbyref(shape),\n\u001b[1;32m   2443\u001b[0m             ctypes\u001b[39m.\u001b[39;49mbyref(dims),\n\u001b[1;32m   2444\u001b[0m             ctypes\u001b[39m.\u001b[39;49mbyref(preds),\n\u001b[1;32m   2445\u001b[0m         )\n\u001b[1;32m   2446\u001b[0m     )\n\u001b[1;32m   2447\u001b[0m     \u001b[39mreturn\u001b[39;00m _prediction_output(shape, dims, preds, \u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m   2448\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, scipy\u001b[39m.\u001b[39msparse\u001b[39m.\u001b[39mcsr_matrix):\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/xgboost/core.py:281\u001b[0m, in \u001b[0;36m_check_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Check the return value of C API call\u001b[39;00m\n\u001b[1;32m    271\u001b[0m \n\u001b[1;32m    272\u001b[0m \u001b[39mThis function will raise exception when error occurs.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39m    return value from API calls\u001b[39;00m\n\u001b[1;32m    279\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    280\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 281\u001b[0m     \u001b[39mraise\u001b[39;00m XGBoostError(py_str(_LIB\u001b[39m.\u001b[39mXGBGetLastError()))\n",
      "\u001b[0;31mXGBoostError\u001b[0m: [01:37:29] /workspace/src/c_api/../data/array_interface.h:233: Check failed: i < D (2 vs. 2) : Only 2 dimensional array is valid.\nStack trace:\n  [bt] (0) /home/codespace/.python/current/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x15c2ca) [0x7f6a36ba22ca]\n  [bt] (1) /home/codespace/.python/current/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x19e9a3) [0x7f6a36be49a3]\n  [bt] (2) /home/codespace/.python/current/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x19fcaf) [0x7f6a36be5caf]\n  [bt] (3) /home/codespace/.python/current/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x413064) [0x7f6a36e59064]\n  [bt] (4) /home/codespace/.python/current/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(XGBoosterPredictFromDense+0x25c) [0x7f6a36bb3d7c]\n  [bt] (5) /lib/x86_64-linux-gnu/libffi.so.7(+0x6ff5) [0x7f6b43149ff5]\n  [bt] (6) /lib/x86_64-linux-gnu/libffi.so.7(+0x640a) [0x7f6b4314940a]\n  [bt] (7) /home/codespace/.python/current/lib/python3.10/lib-dynload/_ctypes.cpython-310-x86_64-linux-gnu.so(+0x12f51) [0x7f6b433eff51]\n  [bt] (8) /home/codespace/.python/current/lib/python3.10/lib-dynload/_ctypes.cpython-310-x86_64-linux-gnu.so(+0xca11) [0x7f6b433e9a11]\n\n"
     ]
    }
   ],
   "source": [
    "def preprocess_data(train_x, train_y, test_x, test_y, target_column):\n",
    "    # Normalize features in train_x (excluding the timestamp column)\n",
    "    scaler_x = MinMaxScaler()\n",
    "    train_x_scaled = scaler_x.fit_transform(train_x.iloc[:, 1:])  # Adjust if the first column isn't the timestamp\n",
    "\n",
    "    # Flatten time series sequences into feature vectors\n",
    "    train_x_flattened = train_x_scaled.reshape((len(train_x), -1))\n",
    "\n",
    "    # Normalize the target column in train_y\n",
    "    scaler_y = MinMaxScaler()\n",
    "    train_y_scaled = scaler_y.fit_transform(train_y[[target_column]])\n",
    "\n",
    "    # Convert to NumPy arrays\n",
    "    train_x_tensor = np.float32(train_x_flattened)  # No need to add a time step dimension\n",
    "    train_y_tensor = np.float32(train_y_scaled)\n",
    "\n",
    "    return train_x_tensor, train_y_tensor\n",
    "\n",
    "\n",
    "def train_xgboost_model(x_train, y_train):\n",
    "    # XGBoost Model\n",
    "    xgboost_model = XGBRegressor(objective='reg:squarederror')\n",
    "    xgboost_model.fit(x_train, y_train)\n",
    "\n",
    "    return xgboost_model\n",
    "\n",
    "def evaluate_model(model, x_test, y_test):\n",
    "    # Predictions on the test set\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    # Calculate Mean Absolute Error (MAE)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    \n",
    "    return mae\n",
    "\n",
    "# Target column\n",
    "target_column = 'ProzessData_ActData_AB1_Temperature_DR1_MassMixingStage'\n",
    "\n",
    "# Preprocess data\n",
    "train_x_tensor, train_y_tensor = preprocess_data(train_x, train_y, test_x, test_y, target_column)\n",
    "\n",
    "# Train XGBoost model\n",
    "xgboost_model = train_xgboost_model(train_x_tensor, train_y_tensor)\n",
    "\n",
    "# Evaluate the XGBoost model\n",
    "x_test_tensor = np.float32(test_x.iloc[:, 1:].values[:, :, None])\n",
    "y_test_xgboost = test_y[target_column].values\n",
    "print(\"Shape of x_test_tensor:\", x_test_tensor.shape)\n",
    "mae_xgboost = evaluate_model(xgboost_model, x_test_tensor, y_test_xgboost)\n",
    "\n",
    "print(f'XGBoost MAE: {mae_xgboost:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Assuming your model is named 'model'\n",
    "torch.save(model, '../../models/lstm_philip2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pickle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/OWL_Factory_Hackathon/notebooks/2_modelling/lstm_philip.ipynb Zelle 6\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bfictional-lamp-g66rv647gwvfpw6/workspaces/OWL_Factory_Hackathon/notebooks/2_modelling/lstm_philip.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m../../models/lstm_philip.pkl\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m file:\n\u001b[0;32m----> <a href='vscode-notebook-cell://codespaces%2Bfictional-lamp-g66rv647gwvfpw6/workspaces/OWL_Factory_Hackathon/notebooks/2_modelling/lstm_philip.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     pickle\u001b[39m.\u001b[39mdump(model, file)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pickle' is not defined"
     ]
    }
   ],
   "source": [
    "with open('../../models/lstm_philip2.pkl', 'wb') as file:\n",
    "    pickle.dump(model, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jhn_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "7ba48d1dfc31994510d1202d5cc1ad7c5341fe2fe772e21645b10ef4af5c8f4c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
